---
title: "West Nile Virus Prediction in Chicago"
author: "gbartusk"
output: html_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
```


```{r research_notes}

# - 33 mosquitos facts: ://www.megacatch.com/mosquitofacts.html
#   > They are cold-blooded and prefer temperatures over 80 degrees. At temperatures less than 50 degrees, they shut down for the winter
#   > Mosquitoes spend their first 10 days in water
#   > Usually, the eggs are deposited in clusters - called rafts - on the surface of stagnant water, or they are laid in areas that flood regularly.
#   > The average mosquito lifespan is less than two months. Males have the shortest lives, usually 10 days or less, and females can live about six to eight weeks, under ideal conditions
#   > Mosquitoes cant fly very far or very fast. Most mosquitoes can fly no more than about one to three miles, and often stay within several hundred feet of where they were hatched
#   > Body heat marks the target. Mosquitoes use heat sensors around their mouthparts to detect the warmth of your body
#   > West Nile virus came to the U.S. in 1999 with an epidemic in New York
#

# - CDC: http://www.cdc.gov/westnile/faq/genQuestions.html
#   > The weather, numbers of birds that maintain the virus, numbers of mosquitoes that spread the virus, and human behavior are all factors that can influence when and where outbreaks occur
#

# - chicago grid: http://www.domu.com/blog/decoding-the-chicago-street-grid-system

# - research paper on WNV (seen commented on kaggle script)
# - http://www.ajtmh.org/content/80/2/268.full


```


## Executive Summary

```{r load_pkgs_udfs}
# - load packages
library(knitr)          # - report writing
library(ggplot2)        # - plotting
library(gridExtra)      # - panel plots
library(dplyr)          # - data manipulation
library(lubridate)      # - date functions
library(Metrics)        # - supervised learning evaluation metrics
library(ggmap)          # - maps
library(Hmisc)          # - 
library(MASS)           # - applied stats methods
library(class)          # - functions for classification
library(caret)          # - model training functions
library(pryr)           # - check memory
library(rpart)          # - regression trees
library(rattle)         # - regression tree plots
library(gbm)            # - boosting with trees
library(party)          # - conditional influence trees
library(gam)            # - generalized additive models
library(e1071)          # - support vector machines
library(neuralnet)      # - neural networks
library(ROCR)           # - roc curves
library(corrgram)       # - correlogram
library(corrplot)       # - correlogram

# - directory paths
dir_root <- file.path("/Users/Gus/Google Drive/dev/kaggle/west_nile_chicago")
dir_data <- file.path(dir_root, "data")
dir_submissions <- file.path(dir_root, "submissions")

# - file paths
path_src_toolbox <- file.path(dir_root,"toolbox.R")
path_data_spray <- file.path(dir_data, "spray.csv.zip")
path_data_weather <- file.path(dir_data, "weather.csv.zip")
path_data_train <- file.path(dir_data, "train.csv.zip")
path_data_test <- file.path(dir_data, "test.csv.zip")
path_data_submission <- file.path(dir_data, "sampleSubmission.csv.zip")
path_map_chicago <- file.path(dir_data, "mapdata_copyright_openstreetmap_contributors.rds")
path_map_chicago_txt <- file.path(dir_data, "mapdata_copyright_openstreetmap_contributors.txt.zip")

# - load R src files
source(path_src_toolbox)    # - udfs

# - set seed
set.seed(123)

```


## Load and Process Data

```{r load_data}
# - load: spray data
df_spray <- load_spray(path_data_spray)

# - load: weather data
df_weather <- load_weather(path_data_weather, impute=TRUE)

# - *** should we stack test and train for doing the processing??? ***
#   since we are applying the same rules to both

# - load: training data
#   dont collapse and use NumMosquitos as weight? test weight all will be 1
df_train2 <- load_train(path_data_train, collapse=F)

# - load: test data
#   there is ALOT of data here, due to simulated traps???
df_test <- load_test(path_data_test)

# - load: sample submission (load in modeling sections)
#df_submission <- load_submission(path_data_submission)

# - join: train and weather
df_wthr_join_list <- join_train_test_to_weather()
df_train_wthr <- df_wthr_join_list$train
df_test_wthr <- df_wthr_join_list$test

# - weather based pc
df_pca_list <- get_weather_pcas()
df_train_wthr <- df_pca_list$train
df_test_wthr <- df_pca_list$test

# - validation set
train_index <- caret::createDataPartition(y=df_train_wthr$WnvPresent, p=0.7, list=FALSE)
df_train_wthr_fit <- df_train_wthr[train_index,]
df_train_wthr_val <- df_train_wthr[-train_index,]
# - check proportions
# table(df_train_wthr$WnvPresentF); prop.table(table(df_train_wthr$WnvPresentF))*100
# table(df_train_wthr_fit$WnvPresentF); prop.table(table(df_train_wthr_fit$WnvPresentF))*100
# table(df_train_wthr_val$WnvPresentF); prop.table(table(df_train_wthr_val$WnvPresentF))*100

# - clearn up
rm(df_wthr_join_list, df_wthr_join_list, df_pca_list, train_index); gc()

```


## Data Visualization 

```{r data_stats}
# - Summary
#   > only 5% of the data is WNV (of 10.5k records)
#   > 4/7 species have no wnv, doesnt seem like a good feature?
#   > the training set has years 07,09,11,13 (train had even years)
#   > year has many wnv cases in 2007 and 2013 ... why??? year doesnt make
#     since as a feature but what even drives that barbell does! Perhaps
#     they sprayed alot more in those years??
#   > We know CDPH sets traps from late-may to early-october, August has
#     the most cases but this is most likely only because its hottest then?
#   > Day / WkDay probably are not important since CDPH lets the traps collect
#     mosquitos Mon-Wed and then tests by the end of the week
#   > spray data only has 10 dates and is not provided for the test set
#     there are alot of forum posts complaining about this
#   > training data has very few obs in May but test data has no May data
#   >
#   >

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - training data 

# - table: wnv
round(prop.table(table(df_train$WnvPresentF)),2)

# - table: wnv by species
#   WNV only shows up for three of the species
t_wnv_by_species <- table(df_train$Species, df_train$WnvPresentF)
t_wnv_by_species
round(prop.table(t_wnv_by_species)*100,2)

# - table: wnv by year
t_wnv_by_yr <- table(df_train$Year, df_train$WnvPresentF)
t_wnv_by_yr
round(prop.table(t_wnv_by_yr)*100,2)

# - table: wnv by month
t_wnv_by_mo <- table(df_train$Month, df_train$WnvPresentF)
t_wnv_by_mo
round(prop.table(t_wnv_by_mo)*100,2)

# - table wnv by day
t_wnv_by_day <- table(df_train$Day, df_train$WnvPresentF)
t_wnv_by_day
round(prop.table(t_wnv_by_day)*100,2)

# - wnv by date
aggregate(WnvPresent ~ Date, data=df_train, FUN=sum)

# - table wnv by weekday day
t_wnv_by_wday <- table(df_train$WkDay, df_train$WnvPresentF)
t_wnv_by_wday
round(prop.table(t_wnv_by_wday)*100,2)

# - Sunrise (always comes up as valid in regressions? ... corr with month!)
aggregate(WnvPresent ~ Hmisc::cut2(SunriseNum,g=10), data=df_train_wthr, FUN=sum)
with(df_train_wthr, table(Hmisc::cut2(SunriseNum,g=10), Month))


# - Sunset: only one value


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - spay dates

round(prop.table(table(year(df_spray$Date), month(df_spray$Date)))*100,2)


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - weather data

# - weather data only available for summer but covers all months
#   and years in train/test set
table(df_weather$Month, df_weather$Year)

# - wnv by temp and month
table(df_train_wthr$WnvPresentF, Hmisc::cut2(df_train_wthr$Tmax, g=5), df_train_wthr$Month)
aggregate(WnvPresent ~ Hmisc::cut2(df_train_wthr$Tmax, g=5) + Month, data=df_train_wthr, FUN=function(x) {sum(x)/length(x)*100})

# - 
prop.table(table(Hmisc::cut2(df_train_wthr$Tmax, g=10), df_train_wthr$WnvPresentF),2)*100


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - decision trees

fit_rpart <- rpart(WnvPresent ~ Latitude + Latitude + Block + Month + PrecipTotalLog + SunriseNum + PC1_temp+PC2_temp+PC1_temp_1d+PC2_temp_1d+PC1_temp_3d+PC2_temp_3d+PC1_temp_7d+PC2_temp_7d+PC1_temp_14d+PC2_temp_14d+PC1_pres_lvl+PC1_pres_lvl_1d+PC1_pres_lvl_3d+PC1_pres_lvl_7d+PC1_pres_lvl_14d+PC1_speed+PC1_speed_1d+PC1_speed_3d+PC1_speed_7d+PC1_speed_14d, data=df_train_wthr, method="class", control=rpart.control(minsplit=40, cp=0, xval=5))
# , control=rpart.control(minsplit=34, cp=0, xval=5)
fit_rpart
# plot(fit_rpart)
# text(fit_rpart)
rattle::fancyRpartPlot(fit_rpart)

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - clean up
rm(t_wnv_by_species, t_wnv_by_yr, t_wnv_by_mo, t_wnv_by_day, t_wnv_by_wday)



```


```{r data_vis}
# - Summary
#   > 

# - load: ggmap of chicago provided by kaggle
gmap_chicago <- readRDS(path_map_chicago)

# - wnv only data
df_train_wnv <- dplyr::filter(df_train, WnvPresentF=="present")
df_train_wthr_wnv <- dplyr::filter(df_train_wthr, WnvPresentF=="present")

# - bubble chart: suffer from overplotting, one solution is binning
ggmap(gmap_chicago) + 
    geom_point(data=df_train_wnv, 
        aes(x=Longitude, y=Latitude, colour=Species, size=Species))

# - boxed contour plot: location of WNV without knowing frequency
ggmap(gmap_chicago) + 
    stat_bin2d(
        data=df_train_wnv, 
        aes(x=Longitude, y=Latitude, colour=Species, fill=Species),
        size=0.5, bins=50, alpha=0.5)

# - create overlay
overlay <- stat_density2d(
    aes(x=Longitude, y=Latitude, fill = ..level.., alpha = ..level..),
    bins = 4, geom = "polygon", data = df_train_wnv)
# - map with overlay (need to fix two level keys)
ggmap(gmap_chicago) + overlay + inset(
    grob=ggplotGrob(ggplot() + overlay + theme_inset()),
    xmin=-Inf, xmax=-87.85, ymin=41.6, ymax=41.7)

# - filled contour plot
#   '.. ..' is used b/c aesthetic is not present in orig data, but rather is
#   calc'd by the contour statistic
ggmap(gmap_chicago) + 
    stat_density2d(data=df_train_wnv, 
        aes(x=Longitude, y=Latitude, fill=..level.., alpha=..level..),
        bins=5, geom="polygon") +
    scale_fill_gradient(low="black", high="red") +
    facet_wrap(~Year)

# - pull ggmap of chicago (need to fix two level keys)
ll <- ggmap::geocode("chicago", messaging=F)
g_roadmap <- get_map(location=c(lon=ll[["lon"]],lat=ll[["lat"]]), source="google", 
    maptype="roadmap", crop=FALSE)

# - plot: trap locations
dplyr::n_distinct(df_train$Trap)
ggmap(g_roadmap) + 
    geom_point(data=df_train, aes(x=Longitude, y=Latitude)) +
    labs(x="Longitude", y="Latitude", title="Trap Locations")

# - plot spray data
ggmap(g_roadmap) + 
    geom_point(data=df_spray, aes(x=Longitude, y=Latitude)) +
    facet_grid(.~Date) +
    labs(x="Longitude", y="Latitude", title="Spray Locations by Year")

# - plot: wnv across years
ggmap(g_roadmap) +
    geom_point(data=df_train, aes(x=Longitude, y=Latitude, 
        colour=WnvPresentF, size=NumMosquitos), alpha=0.2) +
    facet_grid(WnvPresentF~Year) +
    scale_colour_manual(values=c("forestgreen","red")) +
    labs(x="Longitude", y="Latitude", title="WNV By Year")

# - plot: wnv present across years and type 
#   the cases seem to be mostly localized in north and south of the city, most
#   likely because there is alot more greenland there than in city centre.
#   Mosquitos become infected when they feed on infected birds
ggmap(g_roadmap) +
    geom_point(data=df_train_wnv, 
        aes(x=Longitude, y=Latitude, size=NumMosquitos), alpha=0.2) +
    facet_grid(Species~Year) +
    labs(x="Longitude", y="Latitude", title="WNV by Year and Species")

# - plot: wnv across months
#   august appears very significant (compared to july and september), most
#   likely because thats when its the hotest?
ggmap(gmap_chicago) +
    geom_point(data=df_train, aes(x=Longitude, y=Latitude, 
        colour=WnvPresentF, size=NumMosquitos), alpha=0.2) +
    facet_grid(WnvPresentF~Month) +
    scale_colour_manual(values=c("forestgreen","red")) +
    labs(x="Longitude", y="Latitude", title="WNV by Month")


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - Time Series

# - does it make sense to add a lagged dependent variable??

df_ts <- df_train_wthr %>% dplyr::group_by(Date) %>% 
    dplyr::summarise(wnv=sum(WnvPresent)) %>% dplyr::arrange(Date)
qplot(x=Date, y=wnv, data=df_ts)
# - against index
qplot(y=wnv, data=df_ts)


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - Training Variables

ggplot(data=df_train_wthr, aes(x=Species)) + geom_histogram() + facet_grid(.~WnvPresentF)
ggplot(data=df_train_wthr, aes(x=Year)) + geom_histogram() + facet_grid(.~WnvPresentF)
ggplot(data=df_train_wthr, aes(x=Month)) + geom_histogram() + facet_grid(.~WnvPresentF)
ggplot(data=df_train_wthr, aes(x=Day)) + geom_histogram() + facet_grid(.~WnvPresentF)


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - Spot Weather

# - wnv by min temp
g_Tmin <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=Tmin, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by avg temp
g_Tavg <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=Tavg, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by max temp
g_Tmax <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=Tmax, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by departure (from normal temp?)
g_Depart <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=Depart, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by dew point (relative humidity)
g_DewPoint <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=DewPoint, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by wet bulb (similar to dew point)
g_WetBulb <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=WetBulb, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by heating: derived off Tavg (demand to heat a building, just use cool since summer)
g_Heat <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=Heat, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by cooling
g_Cool <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=Cool, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by depth: no variability, same for both
g_Depth <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=Depth, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by snowfall: no variability, same for both
g_SnowFall <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=SnowFall, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by PrecipTotal: LOTS of outliers - dplyr::filter(df_train_wthr, PrecipTotal < 1)
g_PrecipTotal <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PrecipTotal, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by StnPressure: some variability but same by wnv
g_StnPressure <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=StnPressure, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by SeaLevel: some variability but same by wnv
g_SeaLevel <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=SeaLevel, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by ResultSpeed (wind speed): more wnv at lower speed
g_ResultSpeed <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=ResultSpeed, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by ResultDir (wind direction): some variability but same by wnv
g_ResultDir <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=ResultDir, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by AvgSpeed (wind avg speed): more wnv at lower speed
g_AvgSpeed <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=AvgSpeed, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by Elevation: more wnv at low or high elevation (see denisity plot)
g_Elevation <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=Elevation, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')

# - plot: grids based on correlation groupings
gridExtra::grid.arrange(g_Tmin, g_Tavg, g_Tmax, g_DewPoint, g_WetBulb, g_Cool, nrow=1)
gridExtra::grid.arrange(g_StnPressure, g_SeaLevel, nrow=1)
gridExtra::grid.arrange(g_ResultSpeed, g_AvgSpeed, nrow=1)


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - Weather Spot PC

# - wnv by pc1 on temp
g_PC1_temp <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC1_temp, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by pc2 on temp
g_PC2_temp <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC2_temp, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by pc1 on stn pressure and sea level
g_PC1_pres_lvl <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC1_pres_lvl, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wind speed
g_PC1_speed <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC1_speed, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - precipitation
g_PrecipTotalLog <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PrecipTotalLog, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')

# - plot: 
gridExtra::grid.arrange(g_PC1_temp, g_PC2_temp, g_PC1_pres_lvl, g_PC1_speed, g_PrecipTotalLog, nrow=1)


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - Weather Temp PC lags

# - wnv by pc1 spot
g_PC1_temp <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC1_temp, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by pc1 1d lag
g_PC1_temp_1d <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC1_temp_1d, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by pc1 3d lag
g_PC1_temp_3d <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC1_temp_3d, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by pc1 7d lag
g_PC1_temp_7d <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC1_temp_7d, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by pc1 14d lag
g_PC1_temp_14d <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC1_temp_14d, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - plot: 
gridExtra::grid.arrange(g_PC1_temp, g_PC1_temp_1d, g_PC1_temp_3d, g_PC1_temp_7d, g_PC1_temp_14d, nrow=1)


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - Weather Pressure/Level PC lags

# - wnv by pc1 spot
g_PC1_pres_lvl <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC1_pres_lvl, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by pc1 1d lag
g_PC1_pres_lvl_1d <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC1_pres_lvl_1d, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by pc1 3d lag
g_PC1_pres_lvl_3d <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC1_pres_lvl_3d, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by pc1 7d lag
g_PC1_pres_lvl_7d <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC1_pres_lvl_7d, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by pc1 14d lag
g_PC1_pres_lvl_14d <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC1_pres_lvl_14d, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - plot: 
gridExtra::grid.arrange(g_PC1_pres_lvl, g_PC1_pres_lvl_1d, g_PC1_pres_lvl_3d, g_PC1_pres_lvl_7d, g_PC1_pres_lvl_14d, nrow=1)


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - Weather Wind Speed PC lags

# - wnv by pc1 spot
g_PC1_speed <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC1_speed, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by pc1 1d lag
g_PC1_speed_1d <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC1_speed_1d, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by pc1 3d lag
g_PC1_speed_3d <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC1_speed_3d, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by pc1 7d lag
g_PC1_speed_7d <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC1_speed_7d, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - wnv by pc1 14d lag
g_PC1_speed_14d <- ggplot(data=df_train_wthr, aes(x=WnvPresentF, y=PC1_speed_14d, colour=WnvPresentF)) + geom_boxplot() + stat_summary(fun.y=mean, geom="point", shape=5, size=4) + stat_summary(fun.y=mean, geom="line", aes(group=1), colour="black") + theme(axis.title.x = element_blank(), legend.position='none')
# - plot: 
gridExtra::grid.arrange(g_PC1_speed, g_PC1_speed_1d, g_PC1_speed_3d, g_PC1_speed_7d, g_PC1_speed_14d, nrow=1)


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - outliers - apply log transform to normalize
ggplot(data=df_train_wthr, aes(x=PrecipTotal, colour=WnvPresentF)) + geom_density()
ggplot(data=df_train_wthr, aes(x=PrecipTotalLog, colour=WnvPresentF)) + geom_density()

```


```{r pca}

# - data: limit to only weather data
df_train_wthr_pca <- df_train_wthr %>% dplyr::select(WnvPresent, Tmax,Tmin,Tavg,DewPoint,WetBulb,Heat,Cool,PrecipTotal,StnPressure,SeaLevel,ResultSpeed,ResultDir,AvgSpeed)
# - log transform since PrecipTotal is high skewed (+.01 since 0 Precip gives -Inf)
df_train_wthr_pca$PrecipTotalLog <- log(df_train_wthr_pca$PrecipTotal+.001)
df_train_wthr_pca_x <- df_train_wthr_pca %>% dplyr::select(-WnvPresent)

# - table of top correlations
df_top_cor <- top_cor_pairs(df_train_wthr_pca_x, 0.7)
df_top_cor

# - plot: correlograms
corrgram::corrgram(df_train_wthr_pca_x)
M <- cor(df_train_wthr_pca_x); diag(M) <- 0
corrplot::corrplot(M, method="number")

# - plot: correlation and scatter (slow!)
PerformanceAnalytics::chart.Correlation(df_train_wthr_pca, histogram=TRUE, pch=19)

# - pca: percentage of variation explained by component
summary(prcomp(df_train_wthr_pca_x, scale=T, center = T))

# - high correlation groups: (14)
#   > 7: Tmax, Tmin, Tavg, DewPoint, WetBulb, Heat, Cool
#       > Heat and Cool have 50% corr with themselves and look like hockey sticks
#         against Tavg (they are derived values based on temp)
#   > 2: StnPressure, SeaLevel (0.96)
#   > 2: ResultSpeed, AvgSpeed (0.90)
#   > 3: Latitude, Longitude, Elevation (previously included, these are for the trap)
# - no large correlations: (2)
#   > PrecipTotal, ResultDir

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - pca: temp (1st PC:91, 2nd PC: 97%)

# - limit data set
df_train_temp <- dplyr::select(df_train_wthr_pca, Tmax, Tmin, Tavg, DewPoint, WetBulb)

# - inspect - need to scale, otherwise Tmax (which has the largest mean and var)
#   will drive most of the PCA
apply(df_train_temp, 2, mean)   # variables have different means
apply(df_train_temp, 2, var)

# - scree and biplots (center: zero mean, scale: unit std dev)
pr_obj <- prcomp(df_train_temp, center=T, scale=T) 
# - pc loadings and variance explained
pr_obj; summary(pr_obj); screeplot(pr_obj)
# - biplot: scale=0 ensures that the arrows are scaled to represent the loadings
biplot(pr_obj, scale=0)


# - 
pca_temp_obj <- caret::preProcess(df_train_temp, thresh=0.95, method=c("BoxCox", "center", "scale", "pca"))
pred_pca_temp <- predict(pca_emp_obj, df_train_temp)
qplot(x=PC1, y=PC2, data=pred_pca_temp, colour=df_train_wthr$WnvPresentF)


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - pca: station pressure and sea level (1st PC: 98%)
df_train_pl <- dplyr::select(df_train_wthr_pca, StnPressure, SeaLevel)
prcomp(df_train_pl, center=T, scale=T); summary(prcomp(df_train_pl, center=T, scale=T))
pca_pl_obj <- caret::preProcess(df_train_pl, thresh=0.95, method=c("BoxCox", "center", "scale", "pca"))
pred_pca_pl <- predict(pca_pl_obj, df_train_pl)
qplot(x=PC1, y=PC2, data=pred_pca_pl, colour=df_train_wthr$WnvPresentF)


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - pca: speed (1st PC: 95%)
df_train_speed <- dplyr::select(df_train_wthr_pca, ResultSpeed, AvgSpeed)
prcomp(df_train_speed, center=T, scale=T); summary(prcomp(df_train_speed, center=T, scale=T))
pca_speed_obj <- caret::preProcess(df_train_speed, thresh=0.95, method=c("BoxCox", "center", "scale", "pca"))
pred_pca_speed <- predict(pca_speed_obj, df_train_speed)
qplot(x=PC1, y=PC2, data=pred_pca_speed, colour=df_train_wthr$WnvPresentF)


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - pca: all data - corr matrix doesnt justify but just to see
#   the variables are not all correlatied... only the packets used above are

#   dimension reduction on possibe regressors (16 -> 7)
#   pca is not scale invariant, hence standardizing regressors
pca_obj <- caret::preProcess(df_train_wthr_pca, thresh=0.9, method=c("BoxCox", "center", "scale", "pca"))
pca_obj
# - compute new orthogonal regressors
pred_pca <- predict(pca_obj, df_train_wthr_pca)
# - plot: first two components by class
qplot(x=PC1, y=PC2, data=pred_pca, colour=df_train_wthr$WnvPresentF)
# - fit a quick model using linear discriminant analysis against all components
#   glm can only be used for 2-class outcomes
fit_lda <- caret::train(df_train_wthr$WnvPresentF ~ . , method="lda", data=pred_pca)
# - accuracy: train - very low, hard to imagine true model being linear anyways
cm_pca_train <- caret::confusionMatrix(df_train_wthr$WnvPresentF, predict(fit_lda, newdata=pred_pca))
cm_pca_train

```


```{r clustering}

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - k-means
df_train_all <- df_train_wthr %>% dplyr::select(Latitude,Longitude)

km_out <- kmeans(df_train_all, 4, nstart=20)
plot(df_train_all, col=(km_out$cluster+1))

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - hierarchical

# - can only use numeric data!
df_train_all <- df_train_wthr %>% dplyr::select(Latitude, Longitude, PC1_temp, PC2_temp, PC1_speed)

hc_complete <- hclust(dist(df_train_all), method="complete")
plot(hc_complete)
cuttree(hc_complete, 2)


```


## Modeling

*__Logistic__*:
```{r model_logistic}
# - Summary:
#   > 

# - Notes:
#   > caret: http://topepo.github.io/caret/training.html#custom
#   > 
#   > 


# - create cross validation set within training set

# - stepwise regression
df_train_fit_regs <- df_train_wthr_fit %>% dplyr::select(-WnvPresentF, -Address, -Street, -AddressNumberAndStreet, -AddressAccuracy, -DateStr, -WkDay, -Trap, -Date, -NumMosquitos)
# - na vaues will 
fit_all <- glm(WnvPresentF ~ Latitude*Longitude + Species + PC1_temp*PrecipTotalLog + Month + WkDay + PC1_pres_lvl + SunriseNum, data=df_train_wthr_fit, family="binomial")
step <- stepAIC(fit_all, direction="both", trace=0)
step$anova
# - this take MUCH longer as it runs cross validation?
fit_logit_step <- caret::train(WnvPresent ~ Latitude*Longitude + Species + PC1_temp*PrecipTotalLog + Month + WkDay + PC1_pres_lvl + SunriseNum, data=df_train_wthr_fit, method="glmStepAIC", family="binomial")


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - Logistic

#- add weights to account for wnv imblance
w <- 1
df_train_wthr_fit$Weight <- ifelse(df_train_wthr_fit$WnvPresent==1,w,1)
df_train_wthr_val$Weight <- ifelse(df_train_wthr_val$WnvPresent==1,w,1)
df_train_wthr$Weight <- ifelse(df_train_wthr$WnvPresent==1,w,1)

# - fit: train
fit_logit <- glm(WnvPresentF ~ Latitude*Longitude + Species + PC1_temp_14d*PrecipTotalLog + Month + WkDay + PC1_pres_lvl + SunriseNum, family="binomial", weights=Weight, data=df_train_wthr_fit)
# fit_logit2 <- update(fit_logit, ~ . + PC1_temp_7d)
# anova(fit_logit, fit_logit2)
# - print model
summary(fit_logit2)
# - 


# - roc / accuracy: train
pred_logit_train <- predict(fit_logit, newdata=df_train_wthr_fit, type="response")
Metrics::auc(df_train_wthr_fit$WnvPresent, pred_logit_train)
caret::confusionMatrix(df_train_wthr_fit$WnvPresent, ifelse(pred_logit_train>0.5,1,0))

# - roc / accuracy: validation
#df_train_wthr_val$Species <- plyr::revalue(df_train_wthr_val$Species, c("CULEX ERRATICUS"="CULEX PIPIENS/RESTUANS"))
pred_logit_val <- predict(fit_logit, newdata=df_train_wthr_val, type="response")
Metrics::auc(df_train_wthr_val$WnvPresent, pred_logit_val)
caret::confusionMatrix(df_train_wthr_val$WnvPresent, ifelse(pred_logit_val>0.5,1,0))

# - fit: train + vaidation
fit_logit_all <- glm(WnvPresentF ~ Latitude*Longitude + Species + PC1_temp_14d*PrecipTotalLog + Month + WkDay + PC1_pres_lvl + SunriseNum, family="binomial", weights=Weight, data=df_train_wthr)
summary(fit_logit_all)

# - roc / accuracy: train + vaidation
pred_logit_all <- predict(fit_logit_all, newdata=df_train_wthr, type="response")
Metrics::auc(df_train_wthr$WnvPresent, pred_logit_all)
caret::confusionMatrix(df_train_wthr$WnvPresent, ifelse(pred_logit_all>0.5,1,0))

# - create submission file
df_submission <- load_submission(path_data_submission)
df_submission$WnvPresent <- predict(fit_logit_all, newdata=df_test_wthr, type="response")
path_submit <- file.path(dir_submissions, "logistic.csv")
readr::write_csv(df_submission, path_submit)


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - Penalized Logistic

# - http://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression

library(glmnet)
library(logistf)
library(brglm)
library(arm)

# - fit: train / bayes
fit_logit_bayes <- arm::bayesglm(WnvPresentF ~ Latitude*Longitude + Species + PC1_temp*PrecipTotalLog + Month + WkDay + PC1_pres_lvl + SunriseNum, family="binomial", weights=Weight, data=df_train_wthr_fit)
summary(fit_logit_bayes)

# - roc / accuracy: train
pred_logit_bayes_train <- predict(fit_logit_bayes, newdata=df_train_wthr_fit, type="response")
Metrics::auc(df_train_wthr_fit$WnvPresent, pred_logit_bayes_train)
caret::confusionMatrix(df_train_wthr_fit$WnvPresent, ifelse(pred_logit_bayes_train>0.5,1,0))

# - roc / accuracy: validation
pred_logit_bayes_val <- predict(fit_logit_bayes, newdata=df_train_wthr_val, type="response")
Metrics::auc(df_train_wthr_val$WnvPresent, pred_logit_bayes_val)
caret::confusionMatrix(df_train_wthr_val$WnvPresent, ifelse(pred_logit_bayes_val>0.5,1,0))

# - fit: train + vaidation
fit_logit_bayes_all <- arm::bayesglm(WnvPresentF ~ Latitude*Longitude + Species + PC1_temp*PrecipTotalLog + Month + WkDay + PC1_pres_lvl + SunriseNum, family="binomial", weights=Weight, data=df_train_wthr)
summary(fit_logit_bayes_all)

# - roc / accuracy: train + vaidation
pred_logit_bayes_all <- predict(fit_logit_bayes_all, newdata=df_train_wthr, type="response")
Metrics::auc(df_train_wthr$WnvPresent, pred_logit_bayes_all)
caret::confusionMatrix(df_train_wthr$WnvPresent, ifelse(pred_logit_bayes_all>0.5,1,0))

# - create submission file
df_submission <- load_submission(path_data_submission)
df_submission$WnvPresent <- predict(fit_logit_bayes_all, newdata=df_test_wthr, type="response")
path_submit <- file.path(dir_submissions, "logistic.csv")
readr::write_csv(df_submission, path_submit)

```

*__Linear Discriminant Analysis__*:
```{r model_lda}
# - linear discriminant analysis
fit_lda <- caret::train(WnvPresentF ~ Latitude + Longitude + Station + Block + Year + Month + Tavg + DewPoint + Species, data=df_train_wthr, method="lda")
# - area under roc curve
pred_lda_train <- predict(fit_lda, newdata=df_train_wthr, type="prob")[,"present"]
Metrics::auc(df_train_wthr$WnvPresent, pred_lda_train)
# - accuracy 
caret::confusionMatrix(df_train_wthr$WnvPresentF, predict(fit_lda, newdata=df_train_wthr))

```

*__Quadratic Discriminant Analysis__*:
```{r model_qda}

# - lda assumes that regressors are dist multi-var gaussian for each Y class
#   and that there is a single cor-matrix

```

*__Generalized Additive Models__*:
```{r model_gam}
# - smoothing splines 


```

*__Random Forests__*:
```{r model_trees}
# - My guess for why is that random forests are not good at extrapolating. So they have poor performance when new test data has variable ranges they haven't been trained on. In this case, the weather patterns across all the years are very different, so it's hard to predict when that is one of the main inputs. 
#   https://www.kaggle.com/c/predict-west-nile-virus/forums/t/14355/poor-performance-of-random-forests


#- add weights to account for wnv imblance
w <- 1
df_train_wthr_fit$Weight <- ifelse(df_train_wthr_fit$WnvPresent==1,w,1)
df_train_wthr_val$Weight <- ifelse(df_train_wthr_val$WnvPresent==1,w,1)
df_train_wthr$Weight <- ifelse(df_train_wthr$WnvPresent==1,w,1)


# - fit: train 
fit_rf <- caret::train(WnvPresentF ~ , method="rf", data=df_fit, importance=TRUE)
importance(fit_rf$finalModel)

# - accuracy / auc: train
Metrics::auc(df_train_wthr_fit$WnvPresent, predict(fit_rf, newdata=df_fit, type="prob")[,"present"])
caret::confusionMatrix(df_fit$WnvPresentF, predict(fit_rf, newdata=df_fit))

# - accuracy / auc: validation
Metrics::auc(df_train_wthr_val$WnvPresent, predict(fit_rf, newdata=df_train_wthr_val, type="prob")[,"present"])
caret::confusionMatrix(df_train_wthr_val$WnvPresentF, predict(fit_rf, newdata=df_train_wthr_val))

# - fit: train + validation
fit_rf_all <- caret::train(WnvPresentF ~ ., method="rf", data=df_train_all, importance=TRUE)

# - accuracy / auc: train + validation
Metrics::auc(df_train_wthr$WnvPresent, predict(fit_rf_all, newdata=df_train_wthr, type="prob")[,"present"])
caret::confusionMatrix(df_train_wthr$WnvPresentF, predict(fit_rf_all, newdata=df_train_wthr))

# - create submission file
df_submission <- load_submission(path_data_submission)
df_submission$WnvPresent <- predict(fit_rf_all, newdata=df_test_wthr, type="prob")[,"present"]
dim(df_submission); head(df_submission)
path_submit <- file.path(dir_submissions, "random_forest.csv")
readr::write_csv(df_submission, path_submit)


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - Testing

# - fit: random forests
library(randomForest)
fit_rf <- randomForest::randomForest(WnvPresentF ~ Latitude + Longitude + Species + PC1_temp + PrecipTotalLog + Month + WkDay + PC1_pres_lvl + SunriseNum, data=df_train_wthr_fit, importance=TRUE, ntree = 2000)
varImpPlot(fit_rf)
# - auc on train and val
Metrics::auc(df_train_wthr_fit$WnvPresent, predict(fit_rf, newdata=df_train_wthr_fit))
Metrics::auc(df_train_wthr_val$WnvPresent, predict(fit_rf, newdata=df_train_wthr_val))

# - fit: forest of conditional influence trees
#   conditional inference trees are able to handle factors with more levels than RFs
library(party)
fit_cforest <- party::cforest(WnvPresentF ~ Latitude + Longitude + Species + PC1_temp + PrecipTotalLog + Month + WkDay + PC1_pres_lvl + SunriseNum, data=df_train_wthr_fit) #controls=cforest_unbiased(ntree=2000, mtry=3)
# -
fit_cforest
# - auc on train and val
pred_cp_fit <- predict(fit_cforest, newdata=df_train_wthr_fit, OOB=TRUE, type="response")
Metrics::auc(df_train_wthr_fit$WnvPresent, pred_cp_fit)
pred_cp_val <- predict(fit_cforest, newdata=df_train_wthr_val, OOB=TRUE, type="response")
Metrics::auc(df_train_wthr_val$WnvPresent, pred_cp_val)


```

*__Boosting__*:
```{r model_boosting}

# - notes
#   > boosting tutorial: http://webee.technion.ac.il/people/rmeir/BoostingTutorial.pdf
#   >

#- add weights to account for wnv imblance
w <- 1
df_train_wthr_fit$Weight <- ifelse(df_train_wthr_fit$WnvPresent==1,w,1)
df_train_wthr_val$Weight <- ifelse(df_train_wthr_val$WnvPresent==1,w,1)
df_train_wthr$Weight <- ifelse(df_train_wthr$WnvPresent==1,w,1)


# - fit:stochastic gradient boosting
fit_gbm <- caret::train(WnvPresentF ~ SunriseNum + Longitude + DewPoint_1d + WetBulb_1d + SunriseNum_3d + DewPoint_7d + SunriseNum_1d + DewPoint_14d + SunriseNum_14d + SunriseNum_7d + WetBulb_7d + Tmin_1d + Tavg + AvgSpeed_7d + Latitude + Species + Month, data=df_train_wthr_fit, method="gbm", verbose=F, weights=Weight)

# - relative influence of each variable
summary(fit_gbm)

# - roc / accuracy: train
Metrics::auc(df_train_wthr_fit$WnvPresent, predict(fit_gbm, newdata=df_train_wthr_fit, type="prob")[,"present"])
caret::confusionMatrix(df_train_wthr_fit$WnvPresentF, predict(fit_gbm2, newdata=df_train_wthr_fit))

# - accuracy / auc: validation
Metrics::auc(df_train_wthr_val$WnvPresent, predict(fit_gbm, newdata=df_train_wthr_val, type="prob")[,"present"])
caret::confusionMatrix(df_train_wthr_val$WnvPresentF, predict(fit_gbm, newdata=df_train_wthr_val))

# - fit: train + validation 
fit_gbm_all <- caret::train(WnvPresentF ~ SunriseNum + Longitude + DewPoint_1d + WetBulb_1d + SunriseNum_3d + DewPoint_7d + SunriseNum_1d + DewPoint_14d + SunriseNum_14d + SunriseNum_7d + WetBulb_7d + Tmin_1d + Tavg + AvgSpeed_7d + Latitude + Species + Month, data=df_train_wthr, method="gbm", verbose=F, weights=Weight)

# - accuracy / auc: train + validation
Metrics::auc(df_train_wthr$WnvPresent, predict(fit_gbm_all, newdata=df_train_wthr, type="prob")[,"present"])
caret::confusionMatrix(df_train_wthr$WnvPresentF, predict(fit_gbm_all, newdata=df_train_wthr))

# - create submission file
df_submission <- load_submission(path_data_submission)
df_submission$WnvPresent <- predict(fit_gbm_all, newdata=df_test_wthr, type="prob")[,"present"]
path_submit <- file.path(dir_submissions, "gbm.csv")
readr::write_csv(df_submission, path_submit)



```

*__Neural Networks__*:
```{r model_nn}

# - sigmoid transformation: 

# - convert species to numeric for neural networks
df_train_wthr_fit <- df_train_wthr_fit %>%
    dplyr::mutate(
        SpeciesNum = 
            ifelse(Species=='CULEX RESTUANS', 100000,
            ifelse(Species=='CULEX TERRITANS', 010000,
            ifelse(Species=='CULEX PIPIENS', 001000, 
            ifelse(Species=='CULEX PIPIENS/RESTUANS', 101000, 
            ifelse(Species=='CULEX ERRATICUS', 000100, 
            ifelse(Species=='CULEX SALINARIUS', 000010, 
            ifelse(Species=='CULEX TARSALIS', 000001, NA)))))))
        )

# - fit
fit_nn <- neuralnet::neuralnet(WnvPresent ~ PC1_temp + Latitude + Longitude, data=df_train_wthr_fit, hidden=4)
plot(fit_nn)

# - predict: train
nn_result <- compute(fit_nn, dplyr::select(df_train_wthr_fit, PC1_temp, Latitude, Longitude))
range(nn_result$net.result)
pred <- ifelse(nn_result$net.result>0,nn_result$net.result,0)

# - auc: train
Metrics::auc(df_train_wthr_fit$WnvPresent, pred)

# - ?
fit_nn <- caret::train(WnvPresent ~ PC1_temp, data=df_train_wthr_fit, method="neuralnet")


```

*__Support Vector Machines__*:
```{r model_svm}

# - plot a ROC curve given a vector containing numerical scores for each obs (pred)
#   and a vector containing the class label for each obs (truth)
rocplot <- function(pred, truth, ...)
{
    require(ROCR)
    predob = prediction(pred, truth)
    perf = performance(predob, "tpr", "fpr")
    plot(perf, ...)
}


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - SVM - Linear 

# - fit: linear kernal
#   default cost parameter is 1: using a smaller value of the cost param, we obtain
#   a larger number of support vectors b/c the margin is now wider
fit_svm <- e1071::svm(WnvPresentF ~ ., data=df_fit, kernal="linear", scale=FALSE, cost=1, probability = TRUE)

# - prediction: accuracy and auc
pred_svm <- predict(fit_svm, newdata = df_fit, probability = TRUE)
pred_svm_prob <- attr(pred_svm, "prob")
table(predict=pred_svm, truth=df_fit$WnvPresentF)
Metrics::auc(df_train_wthr_fit$WnvPresent, pred_svm_prob[,"present"])

# - use cross-validation to pick the cost parameter (default: 10-folds)
#   > scaling leads to much better results??? w/out=38, w/
tune_svm <- e1071::tune(svm, WnvPresentF ~ ., data=df_fit, kernal="linear", ranges=list(cost=c(0.001, 0.01, 0.1, 1, 5, 10, 100)), probability = TRUE)
# - print the cross-validation errors for each model
summary(tune_svm)
# - tune fxn stores the best model obtained
fit_svm_tune <- tune_svm$best.model
summary(fit_svm_tune)

# - prediction - the cost of 0.001 causes a much larger auc! why is it the best.model???
pred_svm_tune <- predict(fit_svm_tune, newdata = df_fit, probability = TRUE)
pred_svm_tune_prob <- attr(pred_svm_tune, "prob")
table(predict=pred_svm_tune, truth=df_fit$WnvPresentF)
Metrics::auc(df_train_wthr_fit$WnvPresent, pred_svm_tune_prob[,"present"])


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - SVM - Polynomial


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# - SVM - Radial

# - changing the default gamma (0.025) causes this to crahs!!!

# - fit
fit_svm_radial <- e1071::svm(WnvPresentF ~ ., data=df_fit, kernal="radial", scale=F, decision.values=T, probability = TRUE, cost=1)

# - prediction: accuracy and auc
pred_svm_radial <- predict(fit_svm_radial, newdata = df_fit, probability = TRUE)
pred_svm_radial_prob <- attr(pred_svm_radial, "prob")
table(predict=pred_svm_radial, truth=df_fit$WnvPresentF)
Metrics::auc(df_train_wthr_fit$WnvPresent, pred_svm_radial_prob[,"present"])


# - roc plot
fitted_svm_radial <- attributes(predict(fit_svm_radial,df_fit,values=T))$decision.values
rocplot(fitted_svm_radial, )


# - we can increase the value of cost we can reduce the number of training errors
#   but this comes at the price of a more irregular decision boundary / overfitting
# - by increasing gamma, we can produce a more flexible fit and generate high accuracy
tune_svm_radial <- e1071::tune(svm, WnvPresentF ~ ., data=df_fit, kernal="radial", ranges=list(cost=c(0.1, 1, 10, 100, 1000), gamma=c(0.5,1,2,3,4)), probability = TRUE)
summary(tune_svm_radial)


```

*__Combining Predictors__*:
```{r model_ensembling}
# - combine different classifiers by avg/voting



```



